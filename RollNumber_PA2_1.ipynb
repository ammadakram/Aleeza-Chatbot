{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA2.1 - Building your first Chatbot: Aleeza\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this notebook, you will be implementing your own version of the first ever Chatbot, ELIZA.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Follow along with the notebook, filling out the necessary code where instructed.\n",
    "\n",
    "- <span style=\"color: red;\">Read the Submission Instructions and Plagiarism Policy in the attached PDF.</span>\n",
    "\n",
    "- <span style=\"color: red;\">Make sure to run all cells for credit.</span>\n",
    "\n",
    "- <span style=\"color: red;\">Do not remove any pre-written code.</span> We will be using the `print` statements to grade your assignment.\n",
    "\n",
    "- <span style=\"color: red;\">You must attempt all parts.</span> Do not assume that because something is for 0 marks, you can leave it - it will definitely be used in later parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: ELIZA\n",
    "#### The first ever Chatbot.\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/7/79/ELIZA_conversation.png\" width=\"400\" height=\"250\" alt=\"ELIZA Conversation\">\n",
    "</div>\n",
    "\n",
    "This Chatbot was released in 1966 (before the term Chatbot even existed) by Joseph Weizenbaum of MIT. This was a revolutionary program that allowed humans to converse with a computer. As you may have predicted, this was a retrieval-based system, very different from the \"language models\" of today. However, you may be surprised by how well it performed despite the simplicity of the system. Here is part of a conversation someone had with ELIZA, from the original paper (the capitalised sentences are ELIZA's responses):\n",
    "\\\n",
    "\\\n",
    "Men are all alike.\\\n",
    "IN WHAT WAY\\\n",
    "They're always bugging us about something or other.\\\n",
    "CAN YOU THINK OF A SPECIFIC EXAMPLE\\\n",
    "Well, my boyfriend made me come here.\\\n",
    "YOUR BOYFRIEND MADE YOU COME HERE\\\n",
    "He says i'm depressed much of the time.\\\n",
    "I AM SORRY TO HEAR YOU ARE DEPRESSED\\\n",
    "It's true. I am unhappy.\\\n",
    "DO YOU THINK COMING HERE WILL HELP YOU NOT TO BE UNHAPPY\\\n",
    "......\n",
    "\n",
    "The program used certain programmed rules to \"transform\" the input into the output. In order to do this, the program must first decompose the sentence based on certain criteria and then reassemble it based on the predefined assembly specifications. For example, if it is provided with the input sentence, \"It seems that you hate me\", it may be decomposed into:\n",
    "\n",
    "1) It seems that\n",
    "2) you\n",
    "3) hate\n",
    "4) me\n",
    "\n",
    "Of these, (2) and (4) are recognised as key words. The program can then use the remaining sections of the sentence based on pre-defined rules to construct an output. For example, it may be programmed with the rule:\n",
    "\n",
    "decomposition template:\\\n",
    "(0 YOU 0 ME)\\\n",
    "and the reassembly rule:\\\n",
    "(WHAT MAKES YOU THINK I 3 YOU).\n",
    "\n",
    "Here, the \"0\" represents any number of words, whereas the \"3\" represents the 3rd part of the sentence from before. Hopefully, this makes the implementation a little clearer. If not, don't worry as you'll understand how it works once you start implementing your own version!\n",
    "\n",
    "For more details on the original ELIZA implementation, [Click Here](https://web.stanford.edu/class/cs124/p36-weizenabaum.pdf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications\n",
    "\n",
    "As described above, your task will be to first read in a user string, then modify it to provide an output (sometimes subtly, sometimes drastically, depending on the input string). This should be easy to do with the regex library, the specifics of which were discussed in class.\n",
    "\n",
    "\\\n",
    "Your program should be able to handle all 1st and 2nd person pronouns, all 1st and 2nd person subject-verb pairs with the verb be and all possible forms of the verb. If it is unclear what is meant by this, you might want to do some googling.\n",
    "\n",
    "\\\n",
    "An example is as follows:\n",
    "\n",
    "Regular Expression: I am (.*)\\\n",
    "Response: How long have you been %1?\n",
    "\n",
    "Example Input that matches: I am sad.\\\n",
    "Example Response: How long have you been sad?\n",
    "\n",
    "Please note that this is a simplified version of the chatbot, and the original bot had a much more complex algorithm behind it.\n",
    "\n",
    "You will have two tables to store all the logic of your bot:\n",
    "1. Reflection Table\n",
    "2. Response Table\n",
    "\n",
    "These will be described in detail in the cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "These are the ONLY imports you can use for this part of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables\n",
    "\n",
    "These are your reflection and response tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection Table\n",
    "\n",
    "This table serves to convert your pronouns from first person to second person and vice versa. You should list all forms of the pronouns and their corresponding \"reflection\". (eg. i : you)\\\n",
    "\\\n",
    "You should also do the same for all the forms of the verb \"be\". (eg. am : are)\\\n",
    "\\\n",
    "Note: You do not need to add plural pronouns such as \"we\".\\\n",
    "\\\n",
    "This table will be represented as a dictionary. (The first entry is listed as an example below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflectionTable = {\n",
    "    \"i\": \"you\",\n",
    "    \"me\": \"you\",\n",
    "    \"my\": \"your\",\n",
    "    \"mine\": \"yours\",\n",
    "    \"am\": \"are\",\n",
    "    \"was\": \"were\",\n",
    "    \"were\": \"was\",\n",
    "    \"i'd\": \"you would\",\n",
    "    \"i'll\": \"you will\",\n",
    "    \"i've\": \"you have\",\n",
    "    \"you\": \"I\",\n",
    "    \"your\": \"my\",\n",
    "    \"yours\": \"mine\",\n",
    "    \"are\": \"am\",\n",
    "    \"you're\": \"I'm\",\n",
    "    \"you'll\": \"I'll\",\n",
    "    \"you've\": \"I've\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response Table\n",
    "\n",
    "This table is in the form of a nested list. Each entry is a list, with the first term being your regular expression and the second term being a list of possible responses. \"%n\" represents the nth match. You will need to handle this in your code later when replacing the relevant parts of the text.\n",
    "\n",
    "Since this is a fairly large table, you will fill out the regular expressions and the responses in a json file: \"responseTable.json\"\n",
    "\n",
    "\\\n",
    "In this table, you must include ALL subject-verb pairs for the verb \"be\". Do this for first, second and third person pronouns. (eg. I am ...) You must add at least 3 appropriate responses for each of these pairs. You need not account for the contracted versions of the pairs. But, DO include the corresponding question statements for each of these pairs. You can assume there will be no past-tense or future-tense inputs.\\\n",
    "\\\n",
    "Furthermore, in the case that you encounter no matches, you must have fallbacks. Due to this, you must also account for the following cases:\n",
    "1. (I feel ...), (I want ...), (I think ...)\n",
    "2. Subject with an unknown verb\n",
    "3. An unrecognised question\n",
    "4. Any string\n",
    "\n",
    "Include 4 or more responses for these cases as they will likely be encountered more often.\\\n",
    "\\\n",
    "Lastly, add at least 3 more subject-verb pairs, with at least 1 response each. These can be anything you like. Have fun with it (but keep it appropriate).\\\n",
    "\\\n",
    "For example:\n",
    "\n",
    "Regex: I voted for (.*)\n",
    "\n",
    "Response: How did voting for (.*) make you feel?\n",
    "\n",
    "Please ensure the correct order, as you will only be checking the first match later on.\\\n",
    "Once again, an example entry has been provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add entries in the JSON file\n",
    "\n",
    "responseTable = json.load(open('responseTable.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions (Optional)\n",
    "\n",
    "If you wish to modularise your code to make your life simpler in the upcoming cells. Please define your helper functions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n",
    "#tokenizes a sentence into a list of strings with delimiter being a white space\n",
    "def word_tokenizer(sentence):\n",
    "  \"\"\"Splits a string into a list based on whitespace as a delimiter.\n",
    "\n",
    "  Args:\n",
    "    text: The string to be split.\n",
    "\n",
    "  Returns:\n",
    "    A list of words from the original string.\n",
    "  \"\"\"\n",
    "  return sentence.split()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aleeza Class\n",
    "\n",
    "This is the class you will be implementing all of your bot's functionality in. As you will see, this is very straightforward and most of the actual work will be done while writing the response table. We will call our version Aleeza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aleeza:\n",
    "  def __init__(self, reflectionTable, responseTable):\n",
    "    \"\"\"\n",
    "    Initiliase your bot by storing both the tables as instance variables.\n",
    "    You can store them any way you want. (Dictionary, List, etc.)\n",
    "    \"\"\"\n",
    "\n",
    "    # Code here\n",
    "    self.reflectionTable = reflectionTable\n",
    "    self.responseTable = responseTable\n",
    "\n",
    "  def reflect(self, text):\n",
    "    \"\"\"\n",
    "    Take a string and \"reflect\" based on the reflectionTable.\n",
    "\n",
    "    Return the modified string.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Code here\n",
    "    text = text.lower()\n",
    "    if text.endswith(\".\"):\n",
    "      text = text[:-1]\n",
    "    word_tokens = word_tokenizer(text)\n",
    "    for idx, word in enumerate(word_tokens):\n",
    "      if word in self.reflectionTable:\n",
    "        word_tokens[idx] = self.reflectionTable[word]\n",
    "    \n",
    "    return \" \".join(word_tokens)\n",
    "      \n",
    "      \n",
    "    \n",
    "\n",
    "  def respond(self, text):\n",
    "    \"\"\"\n",
    "      Take a string, find a match, and return a randomly\n",
    "      chosen response from the corresponding list.\n",
    "\n",
    "      Do not forget to \"reflect\" appropriate parts of the string.\n",
    "\n",
    "      If there is no match, return None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Code here\n",
    "    text = text.lower()\n",
    "    if text.endswith(\".\"):\n",
    "      text = text[:-1]\n",
    "    for pattern, responses in self.responseTable:\n",
    "      pattern = pattern.lower()\n",
    "      match = re.match(pattern, text)\n",
    "      if match:\n",
    "        chosen_response = (random.choice(responses)).lower()\n",
    "        reflected_captures = []\n",
    "        for i in range(1, match.lastindex + 1):\n",
    "          capture_group = match.group(i)\n",
    "          reflected_capture = self.reflect(capture_group)\n",
    "          reflected_captures.append(reflected_capture)\n",
    "\n",
    "        for i, reflected_capture in enumerate(reflected_captures):\n",
    "          placeholder = \"%\" + str(i + 1)\n",
    "          chosen_response = chosen_response.replace(placeholder, reflected_capture)\n",
    "        return chosen_response\n",
    "    \n",
    "    return None\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your Bot\n",
    "\n",
    "You can use this interface to manually check your bot's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def command_interface():\n",
    "    print('Aleeza\\n---------')\n",
    "    print('Talk to the program by typing in plain English.')\n",
    "    print('='*72)\n",
    "    print('Hello.  How are you feeling today?')\n",
    "\n",
    "    s = ''\n",
    "    therapist = Aleeza(reflectionTable, responseTable)\n",
    "    while s != 'quit':\n",
    "        try:\n",
    "            s = input('> ')\n",
    "        except EOFError:\n",
    "            s = 'quit'\n",
    "        print(s)\n",
    "        while s[-1] in '!.':\n",
    "            s = s[:-1]\n",
    "        print(therapist.respond(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aleeza\n",
      "---------\n",
      "Talk to the program by typing in plain English.\n",
      "========================================================================\n",
      "Hello.  How are you feeling today?\n",
      "i am good\n",
      "why do you think you are good?\n",
      "i dont know\n",
      "ok, lets change the topic a little. tell me about your family.\n",
      "quit\n",
      "hmm, whats your favourite dish.\n"
     ]
    }
   ],
   "source": [
    "command_interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Sentences\n",
    "\n",
    "After testing your bot, you have likely seen that it does not work very well yet. This goes to show the immense amount of work that was put into the original ELIZA program.\\\n",
    "In any case, having concocted all of your (hopefully) appropriate responses, you now need to demonstrate your bot handling all the cases listed above. To do this, you must provide an example sentence handling each of the regular expressions you have listed in your response table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"I am happy.\",\n",
    "    \"You are sad.\",\n",
    "    \"He is tired.\",\n",
    "    \"She is angry.\",\n",
    "    \"It is raining.\",\n",
    "    \"I feel excited.\",\n",
    "    \"I want pizza.\",\n",
    "    \"I think therefore I am.\",\n",
    "    \"John is a doctor.\",\n",
    "    \"I like ice cream.\",\n",
    "    \"I hate Mondays.\",\n",
    "    \"I love music.\",\n",
    "    \"I have a cat.\",\n",
    "    \"I eat breakfast.\",\n",
    "    \"I sleep eight hours a night.\",\n",
    "    \"I study computer science.\",\n",
    "    \"This is a test sentence.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_responses(sentence_list, bot):\n",
    "    \"\"\"\n",
    "    Get a response for each sentence from the list and return as a list.\n",
    "    \"\"\"\n",
    "\n",
    "    # Code here\n",
    "    responses = []\n",
    "    for sentence in sentence_list:\n",
    "        responses.append(bot.respond(sentence))\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "I am happy.\n",
      "you are happy?\n",
      "========================================================================\n",
      "You are sad.\n",
      "why do you think you are sad?\n",
      "========================================================================\n",
      "He is tired.\n",
      "why do you think he is tired?\n",
      "========================================================================\n",
      "She is angry.\n",
      "what makes you say she is angry?\n",
      "========================================================================\n",
      "It is raining.\n",
      "how long has it been raining?\n",
      "========================================================================\n",
      "I feel excited.\n",
      "why do you feel excited?\n",
      "========================================================================\n",
      "I want pizza.\n",
      "what makes you want pizza?\n",
      "========================================================================\n",
      "I think therefore I am.\n",
      "how does thinking therefore you are make you feel?\n",
      "========================================================================\n",
      "John is a doctor.\n",
      "how does a doctor affect john?\n",
      "========================================================================\n",
      "I like ice cream.\n",
      "why do you like ice cream?\n",
      "========================================================================\n",
      "I hate Mondays.\n",
      "what makes you hate mondays?\n",
      "========================================================================\n",
      "I love music.\n",
      "why do you love music?\n",
      "========================================================================\n",
      "I have a cat.\n",
      "why do you have a cat?\n",
      "========================================================================\n",
      "I eat breakfast.\n",
      "why do you eat breakfast?\n",
      "========================================================================\n",
      "I sleep eight hours a night.\n",
      "how does sleeping eight hours a night make you feel?\n",
      "========================================================================\n",
      "I study computer science.\n",
      "why do you study computer science?\n",
      "========================================================================\n",
      "This is a test sentence.\n",
      "what makes you say this is a test sentence?\n"
     ]
    }
   ],
   "source": [
    "therapist = Aleeza(reflectionTable, responseTable)\n",
    "\n",
    "for pair in zip(test_sentences, get_responses(test_sentences, therapist)):\n",
    "    print('='*72)\n",
    "    print(pair[0])\n",
    "    print(pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giving Aleeza Emotional Intelligence\n",
    "\n",
    "In the next part of the assignment, you will be giving your chatbot some emotional intelligence. This will be done by training a simple emotion classification model. You will then use this model to classify the sentiment of the user's input and respond accordingly.\\\n",
    "\\\n",
    "How our logic will work is as follows:\n",
    "1. If there is a match in the response table, we will use the response from the table.\n",
    "2. If there is no match, we will classify the emotion of the input and respond accordingly.\n",
    "\n",
    "The model we will use is a simple Naive Bayes Classifier. This is a simple model that works well with text data. You will be using the `scikit-learn` library to train the model, and the huggingface `datasets` library to get the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "These are the ONLY imports you can use for this part of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will be using the `emotion` dataset from the `datasets` library. This dataset contains text data and the corresponding emotion. You will use this data to train your model. Load this dataset using the `load_dataset` function from the `datasets` library.\n",
    "\n",
    "Next, split the dataset into training and testings sets.\\\n",
    "(HINT: This has already been done for you in the dataset you loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:1429: FutureWarning: The repository for emotion contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/emotion\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the emotion dataset from Hugging Face\n",
    "\"\"\"\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"emotion\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the training split\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "# Access the testing split\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "# Access the validation split\n",
    "validation_dataset = dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 16000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 2000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 2000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)\n",
    "print(validation_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 2)\n",
      "(2000, 2)\n",
      "(2000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.shape)\n",
    "print(validation_dataset.shape)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split the dataset into training and testing sets\n",
    "\"\"\"\n",
    "\n",
    "# Code below\n",
    "train_data = train_dataset['text']\n",
    "train_labels = train_dataset['label']\n",
    "test_data = test_dataset['text']\n",
    "test_labels = test_dataset['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Just like in your previous assignment, you will now train the model and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       581\n",
      "           1       0.90      0.93      0.92       695\n",
      "           2       0.78      0.72      0.75       159\n",
      "           3       0.88      0.89      0.89       275\n",
      "           4       0.86      0.85      0.86       224\n",
      "           5       0.70      0.59      0.64        66\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.84      0.82      0.83      2000\n",
      "weighted avg       0.89      0.89      0.89      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Vectorise the data and train the model\n",
    "\"\"\"\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Code here\n",
    "count_vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "logistic_regression_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('count_vectorizer', count_vectorizer),\n",
    "    ('logistic_regression', logistic_regression_model)\n",
    "])\n",
    "\n",
    "pipeline.fit(train_data, train_labels)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Predict on the test set\n",
    "\"\"\"\n",
    "\n",
    "predicted_labels = pipeline.predict(test_data)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(f\"accuracy: {accuracy}\")\n",
    "\n",
    "\"\"\"\n",
    "Print classification report\n",
    "\"\"\"\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([\"this is very good\"])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "Now that we have our classification model, we can modify our chatbot to use it.\n",
    "\n",
    "First, we will remove the fallback responses from our response table, i.e. the following cases:\n",
    "1. (I feel ...), (I want ...), (I think ...)\n",
    "2. Subject with an unknown verb\n",
    "3. An unrecognised question\n",
    "4. Any string\n",
    "\n",
    "Remove these and save your response table as \"responseTable2.json\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new file \"responseTable2.json\" and add your modified table to it\n",
    "\n",
    "responseTable = json.load(open('responseTable2.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emotion Response Table\n",
    "\n",
    "This table will be a dictionary with the emotions as keys and a list of possible responses as values. You should include at least 2 responses for each emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionTable = {\n",
    "    0: [ # sadness\n",
    "        \"I'm sorry to hear that.\",\n",
    "        \"It's okay to feel sad sometimes.\"\n",
    "    ],\n",
    "    1: [ # joy\n",
    "        \"That's wonderful!\",\n",
    "        \"I'm happy for you.\"\n",
    "    ],\n",
    "    2: [ # love\n",
    "        \"Love is a beautiful thing.\",\n",
    "        \"Cherish those you love.\"\n",
    "    ],\n",
    "    3: [ # anger\n",
    "        \"Take a deep breath and try to stay calm.\",\n",
    "        \"It's important to address your anger in a healthy way.\"\n",
    "    ],\n",
    "    4: [ # fear\n",
    "        \"You're not alone. We'll get through this together.\",\n",
    "        \"Remember to take things one step at a time.\"\n",
    "    ],\n",
    "    5: [ # surprise\n",
    "        \"Wow, that's unexpected!\",\n",
    "        \"I didn't see that coming!\"\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying your Chatbot\n",
    "\n",
    "You will now modify your chatbot to use the emotion classifier. If there is a match in the response table, we will use the response from the table. If there is no match, we will classify the emotion of the input and respond accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntelligentAleeza(Aleeza):\n",
    "    def __init__(self, reflectionTable, responseTable, emotionTable, classifier):\n",
    "        \"\"\"\n",
    "        Initialise your bot by calling the parent class's __init__ method,\n",
    "        and then storing the emotionTable as an instance variable.\n",
    "\n",
    "        Next, store the classification model as an instance variable.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Code here\n",
    "        super().__init__(reflectionTable, responseTable)\n",
    "        self.emotionTable = emotionTable\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def smart_respond(self, text):\n",
    "        \"\"\"\n",
    "        Take a string, call the parent class's respond method.\n",
    "        If the response is None, then respond based on the emotion.\n",
    "        \"\"\"\n",
    "\n",
    "        # Code here\n",
    "        response = super().respond(text)\n",
    "        if response is None:\n",
    "            emotion = self.classifier.predict([text])[0]\n",
    "            if emotion in self.emotionTable:\n",
    "                return random.choice(self.emotionTable[emotion])\n",
    "            else:\n",
    "                return \"I'm not sure how to respond to that.\"\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your New Bot\n",
    "\n",
    "Randomly select 5 sentences from the test set and test your bot. You should see that it now responds with an appropriate message based on the emotion detected in the input (when there is no match)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_responses(sentence_list, bot):\n",
    "    \"\"\"\n",
    "    Get a response for each sentence from the list and return as a list.\n",
    "    Use your new smart_respond method.\n",
    "    \"\"\"\n",
    "\n",
    "    # Code here\n",
    "    sentences = []\n",
    "    for sentence in sentence_list:\n",
    "        sentences.append(bot.smart_respond(sentence))\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "i feel very honoured to have been asked\n",
      "how does feeling very honoured to have been asked affect you?\n",
      "========================================================================\n",
      "i am feeling so reluctant and overwhelmed i try to think of the alternative abandoning that dream\n",
      "you are feeling so reluctant and overwhelmed you try to think of the alternative abandoning that dream?\n",
      "========================================================================\n",
      "i havent been sick in the winter very often since i quit smoking years ago so seldom in fact that now when i do get sick i feel outraged hows that for rational thinking\n",
      "It's important to address your anger in a healthy way.\n",
      "========================================================================\n",
      "i had a fab christmas and an amazing new year with my family and friends and against all odds i feel very optimistic about\n",
      "That's wonderful!\n",
      "========================================================================\n",
      "i mean the idea is intoxicating of course and it feels amazing when its happening but what happens in the morning when you wake up and you have to go to work and so amp so is all up in your shit about something that is completely impractical\n",
      "what makes you say you mean the idea is intoxicating of course and it feels amazing when its happening but what happens in the morning when I wake up and I have to go to work and so amp so is all up in my shit about something that is completely impractical?\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create an instance of the IntelligentAleeza class\n",
    "\"\"\"\n",
    "intelligent_therapist = IntelligentAleeza(reflectionTable, responseTable, emotionTable, pipeline) # Code here\n",
    "\n",
    "\"\"\"\n",
    "Get 5 random test instances from the test data\n",
    "\"\"\"\n",
    "\n",
    "# Code here\n",
    "test_instances = random.sample(test_dataset['text'], 5)\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Get responses from the intelligent_therapist \n",
    "\"\"\"\n",
    "\n",
    "responses = get_responses(test_instances, intelligent_therapist)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Print the test instances and the responses\n",
    "\"\"\"\n",
    "for pair in zip(test_instances, responses):\n",
    "    print('='*72)\n",
    "    print(pair[0])\n",
    "    print(pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
